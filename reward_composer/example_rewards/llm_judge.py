import json
import re
from typing import Union, Sequence, List, Optional, Dict

from ..llm_reward import LLMReward

SYSTEM_PROMPT = """Given some <input_data> from a user and an <output> generated by an AI system, \
determine if the <output> contains any hallucinations.

A "hallucination" is defined as information in the <output> that is not supported by \
the <input_data> or is not factually or logically consistent with the <input_data>.

# Steps
1. Carefully read and understand the input data.
2. Examine the model output.
3. Compare the output to the input data, identifying any inconsistencies or additions.
4. Evaluate the logical connection between input and output.
5. Determine if any information in the output is not supported by or conflicts with the input.

# Guidelines
- Focus on factual accuracy and logical consistency
- Consider both explicit and implicit information in the input data
- Be aware of potential misinterpretations or over-generalizations in the output
- Identify any information in the output that goes beyond the scope of the input

# Examples
## Data to analyze

<input_data_example>
The cat is black and white.
</input_data_example>

<output_example>
The cat has orange stripes.
</output_example>

## Analysis:
{
  "chain_of_thought": "The cat is black and white. The cat has orange stripes. \
The output contradicts the input data because the input specifies black and white, \
while the output mentions orange. The output also introduces a pattern not present in \
the input.",
  "reasoning": [
    {
      "hallucination_type": "Color comparison",
      "observation": "Input specifies black and white, output mentions orange"
    },
    {
      "hallucination_type": "Pattern analysis",
      "observation": "Input doesn't mention any pattern, output introduces stripes"
    }
  ],
  "conclusion": "The output contains two hallucinations: it contradicts the color information \
and introduces a pattern not present in the input.",
  "has_hallucination": true
}

# Notes
- Ensure each step in the reasoning process is clearly articulated
- Be objective and avoid assumptions not supported by the input data
- If the output contains factual information not present in the input, it may be a \
hallucination even if it doesn't directly contradict the input"""

USER_PROMPT = """Analyze the following <input_data> and <output> and determine if the <output> contains any hallucinations.
# Data to analyze

<input_data>
{{prompt}}
</input_data>

<output>
{{completion}}
</output>"""

class LLMJudge(LLMReward):
    def __init__(
        self,
        api_url: str,
        api_key: Union[str, Sequence[str]],
        model: str = "Gryphe/MythoMax-L2-13b",
        max_concurrent_requests: int = 10,
        weight: float = 1.0,
        system_message: Optional[str] = None,
        user_prompt: Optional[str] = None,
    ):
        super().__init__(
            name="llm_judge",
            api_url=api_url,
            api_key=api_key,
            model=model,
            temperature=0.2,
            system_prompt=system_message if system_message is not None else SYSTEM_PROMPT,
            prompt_template=user_prompt if user_prompt is not None else USER_PROMPT,
            max_concurrent_requests=max_concurrent_requests,
            output_parser=lambda x: 0.0 if LLMJudge.has_hallucinations(x) else 1.0,
            timeout=9999,
            default_score=0.5,
            max_tokens=8192,
            ensemble_size=3,
            weight=weight,
        )

    @staticmethod
    def remove_thinks(resp: str) -> str:
        if not '</think>' in resp:
            return resp

        return resp.split('</think>')[1].strip()

    @staticmethod
    def get_json_from_response(resp):
        json_str = (LLMJudge
                    .remove_thinks(resp)
                    .replace('```json', '')
                    .replace('```', '')
                    .strip())
        try:
            return json.loads(json_str)
        except:
            return None

    @staticmethod
    def has_hallucinations(resp: Dict) -> Union[bool, None]:
        if not resp:
            return None
        has_hallucinations_maybe_str: Union[bool, str, None] = resp.get('has_hallucination', None)
        if has_hallucinations_maybe_str is None:
            return None
        if isinstance(has_hallucinations_maybe_str, bool):
            return has_hallucinations_maybe_str
        return has_hallucinations_maybe_str.lower() == "true"

    @staticmethod
    def split_by_separators(input_str: str, separators: List[str]) -> List[str]:
        parts = re.split('|'.join(map(re.escape, separators)), input_str)
        return [part.strip() for part in parts if len(part) > 0]

    @staticmethod
    def preprocess_prompt(prompt: str) -> str:
        # EXAMPLE LOGIC! YOURS SHOULD BE MORE COMPLEX!
        turns = LLMJudge.split_by_separators(
            prompt,
            ['<|im_start|>system\n', '<|im_start|>user\n', '<|im_start|>assistant\n', '<|im_end|>\n'],
        )
        return turns[-1]

    #@timed_execution # don't do it! we're calling super().__call__ which already tracks perf
    def __call__(self, completions: List[str], prompts: List[str], **kwargs) -> List[float]:
        # convert chatml prompt into just prompt content
        preprocessed_prompts = [self.preprocess_prompt(prompt) for prompt in prompts]
        return super().__call__(completions, preprocessed_prompts, **kwargs)
